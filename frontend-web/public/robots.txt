# Robots.txt for Cleack.io
# https://cleack.io

User-agent: *
Allow: /

# Block non-SEO pages
Disallow: /api/
Disallow: /admin/
Disallow: /app/
Disallow: /_next/
Disallow: /checkout/
Disallow: /account/
Disallow: /draw/*/execute
Disallow: /draw/*/filters
Disallow: /draw/*/config
Disallow: /embed/
Disallow: /auth
Disallow: /dashboard
Disallow: /profile
Disallow: /buy-credits
Disallow: /payment/
Disallow: /forgot-password
Disallow: /reset-password
Disallow: /verify-email

# Block query parameters (tracking, etc.)
Disallow: /*?ref=
Disallow: /*?utm_*
Disallow: /*?fbclid=
Disallow: /*?gclid=

# Block duplicate content
Disallow: /*?sort=
Disallow: /*?filter=
Disallow: /*?page=

# Crawl-delay (optional - be gentle with the server)
# Crawl-delay: 1

# Sitemaps
Sitemap: https://cleack.io/sitemap.xml

# Note: Uncomment the following line before production launch to block all crawlers during development
# Disallow: /
